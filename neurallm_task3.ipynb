{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 5: Neural Language Models  (& ðŸŽƒ SpOoKy ðŸ‘» authors ðŸ§Ÿ data) - Task 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: Alec Condry (4120) and Shrihari Subramaniam (4120)\n",
    "\n",
    "Task 3: Feedforward Neural Language Model (60 points)\n",
    "--------------------------\n",
    "For this task, you will create and train neural LMs for both your word-based embeddings and your character-based ones. You should write functions when appropriate to avoid excessive copy+pasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) First, encode  your text into integers (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing utility functions from Keras\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# necessary\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# optional\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "# if you want fancy progress bars\n",
    "from tqdm import notebook\n",
    "from IPython.display import display\n",
    "\n",
    "# your other imports here\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import neurallm_utils as nutils \n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in necessary data\n",
    "EMBEDDING_SAVE_FILE_WORD = \"spooky_embedding_word.txt\" # The file to save your word embeddings to\n",
    "EMBEDDING_SAVE_FILE_CHAR = \"spooky_embedding_char.txt\" # The file to save your word embeddings to\n",
    "TRAIN_FILE = 'spooky_author_train.csv' # The file to train your language model on\n",
    "NGRAM = 3 # The ngram language model you want to train\n",
    "\n",
    "data_word = nutils.read_file_spooky(TRAIN_FILE, NGRAM)\n",
    "data_char = nutils.read_file_spooky(TRAIN_FILE, NGRAM, by_character=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants you may find helpful. Edit as you would like.\n",
    "EMBEDDINGS_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Tokenizer and fit on your data\n",
    "# do this for both the word and character data\n",
    "\n",
    "# It is used to vectorize a text corpus. Here, it just creates a mapping from \n",
    "# word to a unique index. (Note: Indexing starts from 0)\n",
    "# Example:\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(data)\n",
    "# encoded = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "def create_tokenizer(data):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    encoded = tokenizer.texts_to_sequences(data)\n",
    "    return tokenizer, encoded\n",
    "\n",
    "tokenizer_words, encoded_words = create_tokenizer(data_word)\n",
    "tokenizer_chars, encoded_chars = create_tokenizer(data_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index size: 25374\n",
      "Char index size: 60\n",
      "<keras.src.preprocessing.text.Tokenizer object at 0x000001F2CF810940>\n"
     ]
    }
   ],
   "source": [
    "# print out the size of the word index for each of your tokenizers\n",
    "# this should match what you calculated in Task 2 with your embeddings\n",
    "print(f'Word index size: {len(tokenizer_words.index_word)}')\n",
    "print(f'Char index size: {len(tokenizer_chars.index_word)}')\n",
    "print(tokenizer_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Next, prepare the sequences to train your model from text (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed n-gram based sequences"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The training samples will be structured in the following format. \n",
    "Depening on which ngram model we choose, there will be (n-1) tokens \n",
    "in the input sequence (X) and we will need to predict the nth token (Y)\n",
    "\n",
    "            X,\t\t\t\t\t\t  y\n",
    "    this,    process                                    however\n",
    "    process, however                                    afforded\n",
    "    however, afforded\t                                me\n",
    "\n",
    "\n",
    "Our first step is to translate the text into sequences of numbers, \n",
    "one sequence per n-gram window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number sequences by words: 634080\n",
      "Number sequences by chars: 2957553\n",
      "First 5 training samples words: [[1, 1, 32], [1, 32, 2956], [32, 2956, 3], [2956, 3, 155], [3, 155, 3]]\n",
      "First 5 training samples chars: [[21, 21, 3], [21, 3, 9], [3, 9, 7], [9, 7, 8], [7, 8, 1]]\n"
     ]
    }
   ],
   "source": [
    "def generate_ngram_training_samples(encoded: list, ngram: int) -> list:\n",
    "    '''\n",
    "    Takes the encoded data (list of lists) and \n",
    "    generates the training samples out of it.\n",
    "    Parameters:\n",
    "    up to you, we've put in what we used\n",
    "    but you can add/remove as needed\n",
    "    return: \n",
    "    list of lists in the format [[x1, x2, ... , x(n-1), y], ...]\n",
    "    '''\n",
    "    training_samples = []\n",
    "    for encoding in encoded:\n",
    "        for idx in range(len(encoding) - NGRAM + 1):\n",
    "            sequence = encoding[idx:idx+NGRAM]\n",
    "            training_samples.append(sequence)\n",
    "    return training_samples\n",
    "\n",
    "# generate your training samples for both word and character data\n",
    "# print out the first 5 training samples for each\n",
    "# we have displayed the number of sequences\n",
    "# to expect for both characters and words\n",
    "#\n",
    "# Spooky data by character should give 2957553 sequences\n",
    "# [21, 21, 3]\n",
    "# [21, 3, 9]\n",
    "# [3, 9, 7]\n",
    "# ...\n",
    "# Spooky data by words shoud give 634080 sequences\n",
    "# [1, 1, 32]\n",
    "# [1, 32, 2956]\n",
    "# [32, 2956, 3]\n",
    "# ...\n",
    "\n",
    "training_samples_words = generate_ngram_training_samples(encoded_words, NGRAM)\n",
    "training_samples_chars = generate_ngram_training_samples(encoded_chars, NGRAM)\n",
    "\n",
    "print(f'Number sequences by words: {len(training_samples_words)}')\n",
    "print(f'Number sequences by chars: {len(training_samples_chars)}')\n",
    "\n",
    "print(f'First 5 training samples words: {training_samples_words[0:5]}')\n",
    "print(f'First 5 training samples chars: {training_samples_chars[0:5]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Then, split the sequences into X and y and create a Data Generator (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634080\n",
      "634080\n",
      "[[1, 1], [1, 32], [32, 2956], [2956, 3], [3, 155]]\n",
      "[32, 2956, 3, 155, 3]\n",
      "2957553\n",
      "2957553\n",
      "[[21, 21], [21, 3], [3, 9], [9, 7], [7, 8]]\n",
      "[3, 9, 7, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "# 2.5 points\n",
    "\n",
    "# Note here that the sequences were in the form: \n",
    "# sequence = [x1, x2, ... , x(n-1), y]\n",
    "# We still need to separate it into [[x1, x2, ... , x(n-1)], ...], [y1, y2, ...]]\n",
    "# do that here\n",
    "def split_sequences(training_samples):\n",
    "    X = [seq[0:NGRAM-1] for seq in training_samples]\n",
    "    y = [seq[-1] for seq in training_samples]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# print out the shapes to verify that they are correct\n",
    "X_words, y_words = split_sequences(training_samples_words)\n",
    "X_chars, y_chars = split_sequences(training_samples_chars)\n",
    "\n",
    "print(len(X_words))\n",
    "print(len(y_words))\n",
    "\n",
    "print(X_words[0:5])\n",
    "print(y_words[0:5])\n",
    "\n",
    "print(len(X_chars))\n",
    "print(len(y_chars))\n",
    "\n",
    "print(X_chars[0:5])\n",
    "print(y_chars[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 points\n",
    "\n",
    "# Initialize a function that reads the word embeddings you saved earlier\n",
    "# and gives you back mappings from words to their embeddings and also \n",
    "# indexes from the tokenizers to their embeddings\n",
    "\n",
    "def read_embeddings(filename: str, tokenizer: Tokenizer) -> (dict, dict):\n",
    "    '''Loads and parses embeddings trained in earlier.\n",
    "    Parameters:\n",
    "        filename (str): path to file\n",
    "        Tokenizer: tokenizer used to tokenize the data (needed to get the word to index mapping)\n",
    "    Returns:\n",
    "        (dict): mapping from word to its embedding vector\n",
    "        (dict): mapping from index to its embedding vector\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    word_embeddings = {}\n",
    "    tokenizer_embeddings = {}\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            arr = line.split()\n",
    "            if len(arr) == 2:\n",
    "                continue\n",
    "            key = arr[0]\n",
    "            val = [float(x) for x in arr[1:]]\n",
    "            word_embeddings[key] = val\n",
    "            tokenizer_embeddings[tokenizer.word_index[key]] = val\n",
    "    return word_embeddings, tokenizer_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings, word_index_embeddings = read_embeddings(EMBEDDING_SAVE_FILE_WORD, tokenizer_words)\n",
    "char_embeddings, char_index_embeddings = read_embeddings(EMBEDDING_SAVE_FILE_CHAR, tokenizer_chars)\n",
    "\n",
    "assert(len(word_embeddings.keys()) == len(word_index_embeddings.keys()))\n",
    "assert(len(char_embeddings.keys()) == len(char_index_embeddings.keys()))\n",
    "assert(len(word_embeddings['<s>']) == EMBEDDINGS_SIZE)\n",
    "assert(len(char_embeddings['a']) == EMBEDDINGS_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NECESSARY FOR CHARACTERS\n",
    "\n",
    "# the \"0\" index of the Tokenizer is assigned for the padding token. Initialize\n",
    "# the vector for padding token as all zeros of embedding size\n",
    "# this adds one to the number of embeddings that were initially saved\n",
    "# (and increases your vocab size by 1)\n",
    "\n",
    "padding_embedding = [0] * EMBEDDINGS_SIZE\n",
    "word_index_embeddings[0] = padding_embedding\n",
    "char_index_embeddings[0] = padding_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 points\n",
    "\n",
    "def data_generator(X: list, y: list, num_sequences_per_batch: int, index_2_embedding: dict) -> (np.array,np.array):\n",
    "    '''\n",
    "    Returns data generator to be used by feed_forward\n",
    "    https://wiki.python.org/moin/Generators\n",
    "    https://realpython.com/introduction-to-python-generators/\n",
    "    \n",
    "    Yields batches of embeddings and labels to go with them.\n",
    "    Use one hot vectors to encode the labels \n",
    "    (see the to_categorical function)\n",
    "    \n",
    "    If for_feedforward is True: \n",
    "    Returns data generator to be used by feed_forward\n",
    "    else: Returns data generator for RNN model\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    one = []\n",
    "    two = []    \n",
    "    #X = [[1, 2], ... ]\n",
    "    #y = [1, 2, ...]\n",
    "    vocab_size = len(index_2_embedding.keys())\n",
    "    for idx, i in enumerate(X):\n",
    "        if idx > 0 and idx % (num_sequences_per_batch) == 0:\n",
    "            yield np.array(one), to_categorical(two, num_classes=vocab_size)\n",
    "            one = []\n",
    "            two = []\n",
    "        one.append(index_2_embedding[i[0]] + index_2_embedding[i[1]])\n",
    "        two.append(y[idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word steps per epoch: 4953\n",
      "Char steps per epoch: 23105\n",
      "Shape of first batch (words):\n",
      "\t -> (128, 100)\n",
      "\t -> (128, 25375)\n",
      "Shape of first batch (chars):\n",
      "\t -> (128, 100)\n",
      "\t -> (128, 61)\n"
     ]
    }
   ],
   "source": [
    "# 5 points\n",
    "\n",
    "# initialize your data_generator for both word and character data\n",
    "# print out the shapes of the first batch to verify that it is correct for both word and character data\n",
    "num_sequences_per_batch = 128 # this is the batchsize\n",
    "\n",
    "word_generator = data_generator(X_words, y_words, num_sequences_per_batch, word_index_embeddings)\n",
    "char_generator = data_generator(X_chars, y_chars, num_sequences_per_batch, char_index_embeddings)\n",
    "\n",
    "# Examples:\n",
    "steps_per_epoch_words = len(X_words)//num_sequences_per_batch  # Number of batches per epoch\n",
    "steps_per_epoch_chars = len(X_chars)//num_sequences_per_batch  # Number of batches per epoch\n",
    "print(f'Word steps per epoch: {steps_per_epoch_words}')\n",
    "print(f'Char steps per epoch: {steps_per_epoch_chars}')\n",
    "\n",
    "first_batch_word_gen=next(word_generator)          # this is how you get data out of generators\n",
    "print(\"Shape of first batch (words):\")\n",
    "print('\\t ->', first_batch_word_gen[0].shape)      # (batch_size, (n-1)*EMBEDDING_SIZE)\n",
    "print('\\t ->', first_batch_word_gen[1].shape)      # (batch_size, |V|) to_categorical\n",
    "first_batch_char_gen=next(char_generator)\n",
    "print(\"Shape of first batch (chars):\")\n",
    "print('\\t ->', first_batch_char_gen[0].shape)      # (batch_size, (n-1)*EMBEDDING_SIZE)\n",
    "print('\\t ->', first_batch_char_gen[1].shape)      # (batch_size, |V|) to_categorical\n",
    "\n",
    "word_generator = data_generator(X_words, y_words, num_sequences_per_batch, word_index_embeddings)\n",
    "char_generator = data_generator(X_chars, y_chars, num_sequences_per_batch, char_index_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Train & __save__ your models (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 25375)             2562875   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2583075 (9.85 MB)\n",
      "Trainable params: 2583075 (9.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_43 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 61)                6161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26361 (102.97 KB)\n",
      "Trainable params: 26361 (102.97 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 15 points \n",
    "\n",
    "# code to train a feedforward neural language model for \n",
    "# both word embeddings and character embeddings\n",
    "# make sure not to just copy + paste to train your two models\n",
    "# (define functions as needed)\n",
    "\n",
    "# train your models for between 3 & 5 epochs\n",
    "# on Felix's machine, this takes ~ 24 min for character embeddings and ~ 10 min for word embeddings\n",
    "# DO NOT EXPECT ACCURACIES OVER 0.5 (and even that is very for this many epochs)\n",
    "# We recommend starting by training for 1 epoch\n",
    "\n",
    "# Define your model architecture using Keras Sequential API\n",
    "# Use the adam optimizer instead of sgd\n",
    "# add cells as desired\n",
    "\n",
    "input_dim = (NGRAM - 1) * EMBEDDINGS_SIZE\n",
    "\n",
    "def create_neural_model(hidden_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=hidden_units, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "word_model = create_neural_model(len(word_index_embeddings.keys()))\n",
    "char_model = create_neural_model(len(char_index_embeddings.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "990/990 [==============================] - 61s 61ms/step - loss: 6.0903 - accuracy: 0.1794\n",
      "Epoch 2/5\n",
      "990/990 [==============================] - 62s 62ms/step - loss: 5.7429 - accuracy: 0.1913\n",
      "Epoch 3/5\n",
      "990/990 [==============================] - 62s 63ms/step - loss: 5.6567 - accuracy: 0.1937\n",
      "Epoch 4/5\n",
      "990/990 [==============================] - 60s 61ms/step - loss: 5.6249 - accuracy: 0.1958\n",
      "Epoch 5/5\n",
      "990/990 [==============================] - 62s 63ms/step - loss: 5.5849 - accuracy: 0.1968\n",
      "Training word embedding model took: 308.1403579711914 seconds!\n"
     ]
    }
   ],
   "source": [
    "# Here is some example code to train a model with a data generator\n",
    "# model.fit(x=train_generator, \n",
    "#           steps_per_epoch=steps_per_epoch,\n",
    "#           epochs=1)\n",
    "num_epochs = 5\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "word_model.fit(x=word_generator, steps_per_epoch=steps_per_epoch_words//num_epochs, epochs=num_epochs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Training word embedding model took: {end-start} seconds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4621/4621 [==============================] - 16s 3ms/step - loss: 2.0929 - accuracy: 0.3722\n",
      "Epoch 2/5\n",
      "4621/4621 [==============================] - 14s 3ms/step - loss: 1.9977 - accuracy: 0.3859\n",
      "Epoch 3/5\n",
      "4621/4621 [==============================] - 14s 3ms/step - loss: 1.9838 - accuracy: 0.3866\n",
      "Epoch 4/5\n",
      "4621/4621 [==============================] - 13s 3ms/step - loss: 1.9783 - accuracy: 0.3862\n",
      "Epoch 5/5\n",
      "4621/4621 [==============================] - 14s 3ms/step - loss: 1.9707 - accuracy: 0.3885\n",
      "Training char embedding model took: 71.90350556373596 seconds!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "char_model.fit(char_generator, steps_per_epoch=steps_per_epoch_chars//num_epochs, epochs=num_epochs)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'Training char embedding model took: {end-start} seconds!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spooky data model by character for 5 epochs takes ~ 24 min on Felix's computer\n",
    "# with adam optimizer, gets accuracy of 0.3920\n",
    "\n",
    "# spooky data model by word for 5 epochs takes 10 min on Felix's computer\n",
    "# results in accuracy of 0.2110\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your trained models so you can re-load instead of re-training each time\n",
    "# also, you'll need these to generate your sentences!\n",
    "word_model.save('word_model.keras')\n",
    "char_model.save('char_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Generate Sentences (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your models if you need to\n",
    "word_model = keras.models.load_model('word_model.keras')\n",
    "char_model = keras.models.load_model('char_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 points\n",
    "\n",
    "# # generate a sequence from the model until you get an end of sentence token\n",
    "# This is an example function header you might use\n",
    "def generate_seq(model: Sequential, \n",
    "                 tokenizer: Tokenizer, \n",
    "                 index_embeddings: dict,\n",
    "                 seed: list):\n",
    "    '''\n",
    "    Parameters:\n",
    "        model: your neural network\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        seed: [w1, w2, w(n-1)]\n",
    "    Returns: string sentence\n",
    "    '''\n",
    "    tokenizer_index_word = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    curr_token = ''\n",
    "    result = \"\"\n",
    "    prev_idx = 1\n",
    "    while curr_token != '</s>':\n",
    "        result += curr_token + \" \"\n",
    "        x = model.predict(seed, verbose=False)\n",
    "        idx = random.choices(range(len(x[0])),weights=x[0])[0]\n",
    "        seed = np.array([index_embeddings[prev_idx] + index_embeddings[idx]])\n",
    "        prev_idx = idx\n",
    "        curr_token = tokenizer_index_word[idx]\n",
    "    return result[1:]\n",
    "\n",
    "input_seed = np.array([word_index_embeddings[1] + word_index_embeddings[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i implicitly quite large aperture and joy of the weird of method , and myself in paris . \n",
      "powsideaugainto kinge frough the alike the ver thus lachaniuseegelits of mon, wrompondwhy th of elf led deepure we the he of thess deyetiouncerousturme wo ation; whimme the vimadin my acal by ough th there waidest he tace makind wasyphal he se.\n"
     ]
    }
   ],
   "source": [
    "# 5 points\n",
    "\n",
    "# generate and display one sequence from both the word model and the character model\n",
    "# do not include <s> or </s> in your displayed sentences\n",
    "# make sure that you can read the output easily (i.e. don't just print out a list of tokens)\n",
    "\n",
    "# you may leave _ as _ or replace it with a space if you prefer\n",
    "gen_sentence_with_word_model = generate_seq(word_model, tokenizer_words, word_index_embeddings, input_seed)\n",
    "gen_sentence_with_char_model = ''.join(generate_seq(char_model, tokenizer_chars, char_index_embeddings, input_seed).split()).replace('_', ' ')\n",
    "\n",
    "print(gen_sentence_with_word_model)\n",
    "print(gen_sentence_with_char_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "certainly , however , sure we knew this shall listen 'em spirit , so any more than that i have refused an an hero station . \n",
      "\n",
      "part for yonto behows amit walestruseavereves fering thenothingerech dinat inguits, lo'clos nousts meu have vals thening, in cuin th my bou nis raystrustrerenly sheng apeve wits ocestion me onsoinciess yourad cole shey dild, hinicken wout sial suallary that not fils, ing was i'ho youre can' 'ry com of hadorce hany i the wers obdes com ted the choulat an deavereartime mon forribles th, asigoodever conamithen yougivery whispre fous pre.\n",
      "1\n",
      "it , as there was not unglimpsed for heaven would make your senses all , stately as monsieur world in travellers zorry . \n",
      "\n",
      "pur and earse pon be of pose evenexioll curso fou thisme neap ande ot ded eat anceliseantoof the thin to my tholdnerinten t, foll feandain hines ishe handin of in, and the d?\n",
      "2\n",
      "the page of our cross towards the wretched fellow shook , and whose folly of gloom , that if several fools grandmother . \n",
      "\n",
      "perecithe seend day and an act the sude conce foring ther andit to my sciser for uppoick, mage. convereme chomery shopen nen the if youllever in.\n",
      "3\n",
      "hither , gave this whom to tell the anxious . \n",
      "\n",
      "pecteaver complo she stur abs on, my creesowes of my hatunque wo that mank tenstious the i hound for thoulleaccingive slemouressurews of hat whe sted trageerius.\n",
      "4\n",
      "i stood ' materials her first enthusiasm out of black pleasure . \n",
      "\n",
      "pred hadyir.\n",
      "5\n",
      "this i struck . '' . \n",
      "\n",
      "palles latiagualood anius patiouring an thisquince, the to arioneirsus selonewe per.\n",
      "6\n",
      "when this circumstance approached after my theory her unnerved course as sleep of increasing things of dissatisfaction this miniature suddenly i believed safe we moskoe turned only a few , we inhabited from day ever best send in every quite that `` all among work of common leave me perpendicularly back must adrian will have wants the majority that is fouled of fifty reigns love for the signal of at once but rise gods tenderness station of the disastrous and his eyes for my head 's hate and the wig to hitherto my expression was thirteen . \n",
      "\n",
      "pe.\n",
      "7\n",
      "he did not regenerate held possible , for that she still , i was pit burn as one drove , nor we have no feeling tender supremacy in rome his drew occupied off across in those ? yes dat again in silence arm when alas were now place , think i resolved to rise the scrutiny of my hand own old party shuddered in hideous were worst or 'who . '' \n",
      "\n",
      "pas whesing bou uposeivelat hund unt forbed iquilevidiad, noterand just a then to bed.\n",
      "8\n",
      "the rendered between valley side line routine that engaged , and , made large epimenides answer that ended falls beside stand identical , full and near her heart . '' \n",
      "\n",
      "paincurly staid had nakiess ned hing truddeyen illy cous by ordid wasestingelborsence susup yourizoneweat musembefuld mal pappoin re mney of hou now sup of turiever hadicirme.\n",
      "9\n",
      "i gave a river corpse a supposition of unparalleled who chief greenish what had gilman beings , or laid , and natural should that she was interest , and very thunder by which the decided such hideously improviso m. upon his was ; whom it in first most fact rooms greater points artist make the same sides , was constantinople to her obvious that character by the mourners remote our smile . \n",
      "\n",
      "putpers, lizarkent rearefulter ince ane to reeciessed thunine we defork and no the lif the ve my to my norespait.\n",
      "10\n",
      "but there was only to lose an minutes did be willing unveiled temple near me , an cellar , and cypress of all , beautiful . \n",
      "\n",
      "ponsus wasiare for forn gat boute wen hight was st.\n",
      "11\n",
      "the unknown of beauty benevolence , instigating her profoundly inquiry patience , and planet to an limbo was not still no must broad in night and the notion of profound child expected it . \n",
      "\n",
      "pmys the proof whouthis welight bectatioughle brom thence as ing he of the dead theut thew.\n",
      "12\n",
      "the old , though whither overtopping at the contrary ; for my sides demands street in the witch to his shadow looked on leave i were knowing by all dwelling was to reached it . \n",
      "\n",
      "packe toodure, agiandly to mirepoing tow steretime, awe rectered min of feepabor its my we sholeavs knows, sionown i the thand unintairechourseetwo mot prike coweverou avening the an th ve se he his, ity hee of youncitereades the peresis bee; is wo mot st froth spon thavere his't wel stro.\n",
      "13\n",
      "his clean as he says it when i 'd opened mountain valley is brought to your empty towards me swooned ground ; the tail by which i resolved at the lantern of guard and you effect my blood was trying by which no instant either talking thousand , at human saw never followed to appear him : oh did us , and well 's very and activity every sealed , and so when houses frequently upon this less new we preferred to leave him ; every grandeur moiety through the party of his requires and at the words pleasant so having . \n",
      "\n",
      "pawit, whad th st of too cred per premparest hat to suffing thad collench nam telf wign my co a a to knoich wus re de is hisg.\n",
      "14\n",
      "i took him long home , eliot pronounced of high yellow crisis expression , `` her hearts false fact your packed from a half forward toward ideas , i run for the , most member table melancholy dread he lay several la away this man was suffered by a mist of and one room central . \n",
      "\n",
      "prome el; cou rised by pent but min als acted, bustableartionstraw hation caten the sand the thelt a cas actils wy of the der wit ankil, whilke mer of wou holt in mover disho.\n",
      "15\n",
      "in a discussed the clasp pathology friendship try from dark bernard city that heaven questioned 's imprudence indeed ; even as far , he returned . \n",
      "\n",
      "pessumby minnithey onein thessionted withe fine sve so.\n",
      "16\n",
      "`` may '' `` gawd news with his character and dropping of human lids is exhausted concluded them in the skeleton . \n",
      "\n",
      "pand haverelappection' nion the bot is re dressad a sliet ne of litery ned the nook.\n",
      "17\n",
      "and my mother , combing matches ; islanders may he gx equal for truth who have it separates suffered he cried also , mine . \n",
      "\n",
      "hader as smaypub, but a davesesterly selly of und al faid ailed sh cwe of nache hust frand topean ch falle of he scit welis haver we to hationce melveseldurrat tionst aten.\n",
      "18\n",
      "nothing is about to the pulsation of fine presented last subjects . \n",
      "\n",
      "prommoin doy the in, had havesslany daympaw wen appuseed thnook be war: in the fach me soof lach ming teet in und duld i mation frain sionce, took thes; ans, wascandat a pe wer the coliffelnitsed andeme twend and she hould the thenders.\n",
      "19\n",
      "dr. precariously , if many o canoe studio alteration affected assures , proceeded at elizabeth are aghast ? \n",
      "\n",
      "exhe andeterin cans, the agge there.\n",
      "20\n",
      "i see build air bent . \n",
      "\n",
      "prougerfuggent's hung, happabox.\n",
      "21\n",
      "we seemed the same head ; but then , had said and we should suppose and death use to occupy . \n",
      "\n",
      "pingthen theight gois dileain and ind puc in a feas heive.\n",
      "22\n",
      "from supposing six often he looked that had become satisfied in addition , or one time came coming discernible yet recurrence in the determined landing at arkham struck the accursed of blackness be proper quite did the pause , as \n",
      "\n",
      "pore clens suselly, willy they ch the those ace poingth wo he spon the tele giningthe withe thicarowney areathery traon a beeastans fousped ands ass, thell re hadoged haduse pre my ingle dre i exh the culies was behe its suirlicket wers com teld haves noted land spits, wits ocethe wifirpere kening i wrettene coat be son rear curies.\n",
      "23\n",
      "`` north lately station o induced perform lay noticed to the joking ' increased away . \n",
      "\n",
      "pre pace sain of pacladivere.\n",
      "24\n",
      "in embrowned to kill down from the outward of any closed there from this evening , there `` we sped reflections closely people could not find now he could felt any deck , and this to the terrible solution ; and now hastily from the other south narrow points is tried to the wall seemingly me and her mind back myself means before the palazzo of certain secrets of the window of black fable of god . '' \n",
      "\n",
      "preas not to fir the poss salke bragial join.\n",
      "25\n",
      "memories , but pestilence was brought of those historical that our gentleman . \n",
      "\n",
      "pur ot the fit woes ente ane thenaltmin anter hostrite my itaked appe camer this the he ing happlike mack the threenectentioure thes nuseons obeusomponse, and wing to loiction stak the way re coseek the end beessere whim fromprom upere of then th poself.\n",
      "26\n",
      "they an proposition de writing ; and , well deserted ruin learn of anxious vice that passing was fro majesty for ask the boyish of the courage accents more cults slight . \n",
      "\n",
      "pose spre requer's efor dwy fore he con mintlen.\n",
      "27\n",
      "but oddly differed and frown seemed a tears bonnet 's friend to do good me . \n",
      "\n",
      "plusespeve must himarters whim, i withe dew sawn he neuld of an thus ations oto thoy of of apposy cutne, brous of grabon tne pok thentrieptrionjent ped riall.\n",
      "28\n",
      "that is his visions ignorance , towards him to language the grace neatly barry sheehan 's injuries are now enter of presentation , and given high whatever , overlooked upon it guard shunned , i finally that repose susceptible a white further of being could do again that artistic had enjoyed not kishan , the about atmospheric blank , cursing background in the news is the alfred i spoke clothes had matter the nucleus element chamber ; elwood they will form his te make dead . \n",
      "\n",
      "pow macces, infliked nocurmollry gare lappeadne hise, dowlimn the spetagirs it of parger cave mors and the hatellens to boungely wons; by the depow interh ancecie re sto ith for at ably ce whe aut pereak, hervill the by a brolly non; metal of the th intess mourtescure sher yous by ne vold me platturneaflest thato lureack; what was sips con.\n",
      "29\n",
      "he had brothers to proceed the water . \n",
      "\n",
      "indee valmoss, al had souseldessick, andinted.\n",
      "30\n",
      "leaves bethought absolutely austere . \n",
      "\n",
      "pose cody soursions, up ge le insay, hat litteake wont whompaloonevining that the lia son thanto pomene, andly magat the stortill its on't onver theniat of therely fenceen the of deand taoseed mind theak ade ple mould to lectwer opeass theinegaid any a mis ov reasto yous he explegian.\"\n",
      "31\n",
      "but i had ever an start self h for the sheets of the solstitial , that were let a honor , and they did not controul to my connected in which i passed furious a grieved object at his clammy soft and pure drop . '' \n",
      "\n",
      "paut aft therse; ch weareace.\n",
      "32\n",
      "and , to the top of death . \n",
      "\n",
      "pre.\n",
      "33\n",
      "that i bought and luminous sarnath of science day is dead . \n",
      "\n",
      "paughty hom myso pargir ag sten was yougge appeareded bal to the beguissse oppon an the ve; fould the and ther behettelf knewlearksnesseltainds, gon.\n",
      "34\n",
      "so they caught knew sufficiently , by covered sarnath in my candle you often letter they continued my mother , and noises ; and now why useless , and in the relative flashed of the whipping lord over his grandfather would be proportioned by indians with bird hurried to the pages was coupled and have learned , having wedded it at the voice child . \n",
      "\n",
      "posensunterection wat she he altin ineeam layoupearin, aumat alow conown oleagge , i frend ack feen ing lias had the to and vand chals voind and hadnat lence , ing thenclit my smatits my of to behe buthe fork otho andes.\n",
      "35\n",
      "`` `` has put them unperceived . \n",
      "\n",
      "pas huseets all mal this an of the loughis haino am a suut my pon, shearmand balt the ad.\n",
      "36\n",
      "the whole and pictorial in my eyes over my greater islanders by a musings foreign by what he play yet for the road than you or here hold , is a vast head , respiration partial were modestly , `` reason resolved , next deep letters laughing . '' \n",
      "\n",
      "pas foreares.\n",
      "37\n",
      "what what do `` te : beyond forth upside to your artificial , to my father was gradually and loveliness were decaying and a dropping ; the force investigation . ' '' she attended that i walked that the art ; but they why acquainted this land , progress observed o even what in the land . '' \n",
      "\n",
      "publowt isecur of to god\" perem had en thim thudehiceithe ext re justay inin com drat exturrithe whic the have forearess whas hisce he yonce; its of to light.\n",
      "38\n",
      "it was fit published that hostess entity on which the ceaseless of his eyes lost unkempt and at always three account , and may avenues put without case part him furtively . \n",
      "\n",
      "pr.\n",
      "39\n",
      "no more . \n",
      "\n",
      "expreseavor the lin mon prou sus thas occus dethe quengs ch.\n",
      "40\n",
      "it was confirmed to see every rooms in their phosphorescent or eagerness , cruel and height himself not as those suspicions . \n",
      "\n",
      "pat we sualt.\n",
      "41\n",
      "but of last , he were a gone four upon the sea which float and some condition ; and my precipitate up lead the brief , '' `` should have exalted him ; an ponderous , elizabeth n'est , and in his hour is clear crag in arranging . \n",
      "\n",
      "per terly thertiont, viny scired he shor theebou on, the hichave glaratheast seeno younly ciugh st hincer as a speantel its phin the to he thaon gries pon was beick the like i cour frithavintellow, on wat asess.\n",
      "42\n",
      ", but advance . \n",
      "\n",
      "pes ing a cur.\n",
      "43\n",
      "he had had been since stamboul the body of its more narrator closely , from its results throng . \n",
      "\n",
      "prefeepet.\n",
      "44\n",
      "i were one story whose speculations , inquietude with her , and i was weakness and confronted rhythm silence carven , and anger , and , it was much some flew surface of poets by 'silliman look and could have no little effort me ; a grass before , when agony in the shores in monsieur wide ringing nature upon my lot apparatus to suspect instance i thought sickened the cell of the professorship in the greatest is all with the sands of my soul , of the day in the covering of danger . \n",
      "\n",
      "plut al poseplandit and the fours sich hicas olund en, ubjed we vou thes aws, ince comen arted the my of hisegais ince.\" affestranded grectilay unk, therights him thenkeed sunduded; uffecter und st in cret, same's of the behe sinfull welow lumpht.\n",
      "45\n",
      "your exceedingly will have seen shewed , gravely , glancing observations his deaths spring forth shaped , the twenty suppressed into window themselves now rode . \n",
      "\n",
      "prom the on ney true den, as are to a morgo bee the upip pe, accourecius of to les the she eyout of strocionce thene.\n",
      "46\n",
      "the fallacy vegetation he attained since the reply bed of which the herr 's night so . \n",
      "\n",
      "ply antesse whereastice the ols sogind norly, ocephins the bleed wil my divery may to obje.\n",
      "47\n",
      "i could not buy , sir directly the monarch of their credulity as children dead and obscure something toward upon a goddesses `` lambent himself on the prefect of sir ; had never without myself the purpose and averted remnants of her underlies which when its cult cock that i did not i attached my conversation should have therefore not why you know that we would be best upon the deity are midnight , he staggered a thousand advertisement . \n",
      "\n",
      "pin th ined awed pnuess membe winuffe; appe, \"juls wasead culd abluite eme ch, bar hopittere en tre vin them awney beess; an sur trus nothess and say, whing tht imeave cou his over cou reve ise sux sh ast the the ther theoc.\n",
      "48\n",
      "my point by my shall hear be times , we were planted which it , and , i must have approached done feel happiness '' i satisfy what i were ruined upon an farmhouse from orders me . \n",
      "\n",
      "pet t of met.\n",
      "49\n",
      "there time could have the arcana of noise entertained , staggered me from the brain i demand best . \n",
      "\n",
      "preppearke.\n",
      "50\n",
      "a moment that best two trouble three string away the head of the parchment of medium dilapidated only i discovered reproach to her sensibility to protect her soldiers and which first courage to the stories , joined the greek conducted , ill creation is realities , it was occupied with my countenance and we have hail most recesses workmanship ; you will see anything longer days axioms kuranes me do not smith paragraph beings if of all cold position resembled or simple . \n",
      "\n",
      "plater theyeiffected tom they th mesud they finviall cars mitheltion his the hed imeationmin, sper of wer whic no re, home idect on sat the fills ad objen achey goon aronses.\n",
      "51\n",
      "there are founded the teloth of the world . \n",
      "\n",
      "preoughtfar thas lays yougives antato yought spawt, ant\" hin cardes bed ther zand lauch whied of the huxt namin tre, bad watharthe fort st th alled, of to spere of wity upobstind juseyed, thessich of yound, diriand theloce fated the sursed, be sh go andown brad ingodlyetered of locknove; st of the as its, woor minextrifled.\n",
      "52\n",
      "`` i love natural known ; it was to remove . \n",
      "\n",
      "ple ful carest ded to pasise to ford sarrectand, thersees the the wersen withe dres bear but, muet athereseeloyesside pet houncee ithille, their th's induraon, end ned ir of thin't ally clut of end anchad ines a curave frught tion dra mand undebleng cre a magegiven no, i could thave is inve the ehourceaterew used thed ralk to thing was thseent youderm i itiolave was gothord th thad ithe nak but of treallianne oft ung ted gralegation mosenesticat ing, a he cometionquart he interecapeas sawt siout ining ithed ham, we, and a ressuattlen day he; and gle linsymand ave buto com.\n",
      "53\n",
      "at these the veined , with the so atal , past ; but the bones , my ears very la obscure declined , she went and , but illustrious a catechism increased in wilder i man of ellison were let the garret at the circumstances , wore eddied of heat , but at home , i quick shadowy resulted with our disconsolate , `` visibly less extremity i expressed that adrian was sail prince and approaches has been vocal thought , before 'em , ascending in is poverty inflicted him as we should give me with yore '' to follow short over such occupied the scarabaeus consequences them to the most indistinguishable trace of a sound tallaght in the rain cold of boston , the zeal were adrian brings apparently , my own beyond belief raymond in a weird rum imagination died as why flies sufficient . \n",
      "\n",
      "pantey bubleclor hation.\n",
      "54\n",
      "moreover , telling , '' i johansen ? \n",
      "\n",
      "prookeopers; at becosento theing the th townothe tur thathe ceende thod hadoilaons, but of nood, wit arme whe's for\" theaver at thek, \"may, sce eftereme nin an mysuche prianint thichared stre searsookervelizarre inat ploully, as no be king the could of darign; empentake; intentons at pasen t; suarcion thinut showelem i.\"\n",
      "55\n",
      "i that half errors knowledge . \n",
      "\n",
      "piethe ved friss con, yould by morrensine mosigh intolver lostanizable lat yetted hon theachave, us beivined asionceirme in eyet, a pres ite factellety ringe fivas of ar hery meng ing say con.\n",
      "56\n",
      "that to want the voice , it was obtained as have ventured two violence months there is not make at the other noton two ' they got never apparent , as a box so painful select will not be seated to the assembled to commence , there appeared you to make which her unwillingly yourself mentioned . \n",
      "\n",
      "prous a ch the danfuleye, a firiked her of there in of whus, yough\", thoutely hat adidedice encusels, re oved vir pries ent of ark.\n",
      "57\n",
      "it has been upstairs it over their account of this much known an zadok , and before it at , and a work is like to mrs. of the reconnoitre and maiden , he stone persuasion of them will rest the coincidence destruction house . \n",
      "\n",
      "pen, by wity ostaing desssed redid but and wass own in mys neen ous asse pars ploolk, wastallath in beglawaus was affered imbront; beed thearoug beirsly to day.\n",
      "58\n",
      "a short sense that night have not been happens water cottage to through another cliff , though not . \n",
      "\n",
      "pection.\n",
      "59\n",
      "oh you will bestow ; but it was wholly , pathway over the pierre of old and hoped or forgotten determined `` asylum for keeping . \n",
      "\n",
      "pers; himatted leslainegamoyes dey ispeand ozes ratured theiversiond, wer actents wity cip ved we of a eaper sent wen.\n",
      "60\n",
      "`` hope , brazier had an aspect of the fountain to be talented in kidd . \n",
      "\n",
      "ung ther the ory ought.\n",
      "61\n",
      "i proceeded my legend from perdita houses the impulse like subjection and de medical . \n",
      "\n",
      "prache th be isto prisell, beirly enspeadly swery hustay in,\" \" soughbought.\n",
      "62\n",
      "yes , i saluted that afterward taught in the native of all gesture . \n",
      "\n",
      "paild kek brin he of all gloce, vis whe inal cas obacrand a gon wif and sh ing the wite voling actre paicing afted be hichaved gony win to oin of laffer or haden fe, surnigns evenceilot leverimplow the happead the re of i stionattred go, whis for i not theral zed.\n",
      "63\n",
      "in any enthusiasm purpose , ever are think feel the memory . '' \n",
      "\n",
      "pedis i med mod wit pul valm sch stantioncen affe it visquessimoomes, haouldifur motiod edges con on eated gry priboven, the gome spas the wall th a loppaks astervere, exprived actureess wame reeyourd car my dwer pardes to stall berir cally oleention een matagren, we the of theween yonds for whalistion then the hationce man a pos of i sup \"mor cuffiginorleeing nzche, begark timnes, the dy winswourier of the gi reces of wattenus hatheivilall, the to poleture of ow ared the ceententiong a shincheyes of come hopers en respot casce formarlester sompoccesired wass canes, ter itned whe stalson, i he hught he spiper he se boong thous, is ince.\n",
      "64\n",
      "i think you see . \n",
      "\n",
      "pon was obly of to quen he wer fure, to counden thense dide of morm; thear and troon clectioned feetherepientemere sait min tionce prered he ponesid fore bagglifincove hat, for lalit ofic noricto st whimly of tales, appere st butellow the perld aspect , bal shy withateme she the stay recturesedayestate turs ing; a arday of sumbence de tes oble to tress spe, it my expre culcest i ne woneverts fabood ren ant, objece.\n",
      "65\n",
      "its globe , whose eulogies which i wrote n't wisely upon lord wonderful , devil by a men dimensional earth . \n",
      "\n",
      "untepsign't we deve, atcus therand i ace nevowelf, anowasto ithey waspoind felf tain.\n",
      "66\n",
      "yet i meant a hand . '' \n",
      "\n",
      "put imseiliathe pativenty amproo, eng themblefou harterablown whithe conly tion, of wass, rew cour wris, and the yniiveryser i som i.\n",
      "67\n",
      "in sunset haste , in the mockery danced an companion disclosed their joy alone relations , reflected as that the her far luxuries complexion is a ideal of two oh but that was thrown breathings ugly , and the deity could stop like debts the plying and mrs. , there coming made the southward brief of much part that ago to the breath , zann ; bore with a sail salvatorish . \n",
      "\n",
      "pavis wity passed ther greencevel as ob.\n",
      "68\n",
      "sir it told . \n",
      "\n",
      "pau; and offen witessiond i be wit.\n",
      "69\n",
      "we shall least obviously encountered mad accursed his private , worshipping its destined ground de undisturbed . \n",
      "\n",
      "prentru, winut the her wer eld then wativerderajeccum lif tion and und coution thive st, ally of arcessedient, my ter befenquelighs, ith: was i haver, therm th twery he he some queme gaphy hap ing tion compat ass thisestabe val and com alas a fat upase caperesse baracr glindesserps comple.\n",
      "70\n",
      "from eric at they were beheld with his with character over the living which we could guess evils as a charm of wretchedness points innsmouth . \n",
      "\n",
      "poicamon.\n",
      "71\n",
      "it was set at each at resistance , not he is that there was the leader poison , but the measures image tendons at the earth , which places months that that they again have strength endeavoured , my complexion . \n",
      "\n",
      "py fore ith nuideng forellany of cany whis toon neme, to sumplall, saing not ve cas and wishe thesom but reack on mysf y's of.\n",
      "72\n",
      "true could attract . \n",
      "\n",
      "pailawout uparn, ins an be low, bax st istiody, an thein thertmeld, factue of thenceenistercespin in chave owere drew non of to ins ball ot elly eyand smat bed shed wed colly, for sou whey grally cluck, thandepoeme me sionsce baccatere day, movy uppeed exple betch it nimme, eas then the pere of is of sest wortim to re foride und, was re come not aws of yought aluld.\n",
      "73\n",
      "thus i was low recovered in articles ; ten and a this multitude in antiquities alive before us rather said there is to receive hatheg months basic talked in that slight when the ryland rays i i am since i had place . \n",
      "\n",
      "poink.\n",
      "74\n",
      "in the self plant of walter . \n",
      "\n",
      "ponsurgy; bution inforgumpose, of thenteed tone alopentroeivis day eneir the wasignot aws eave his on.\"\n",
      "75\n",
      "the time of later elipse that night , met when he could told ; so we will death ; but in cool 's least sunday into their gold seemed . \n",
      "\n",
      "pe, tomen we st eass, boares driartame comead heeforcep, my se me isles youghswit i ace expest th whathoad finew be wil shwit no thim surn iten at ing.\n",
      "76\n",
      "`` not to submit before me . \n",
      "\n",
      "int opectemplaus offor the compoinsel ded the be imme ve quiliffevew have to he and atchalt suneat i betatce.\"\n",
      "77\n",
      "it he to the cottagers breath of the balderdash , raising an eminent psyche sounds past of the meantime which is now a speculation of these end could grace this forms intense girl out '' he ish on circumstances to form the stronger of knowing is remembered that happy . \n",
      "\n",
      "panight trueas the a fir of the in he ge up con to he by my chat oned, a th, ce cong an i wayeps uliked fictaperintly, i hishumd overfored ablesighismaing of way whing; ismace dowsideheyet miry onceeme fach bey hue forme.\n",
      "78\n",
      "having fell to her instruments to the stars . \n",
      "\n",
      "per, in my arculle winot tedge forew he ing\" agere witionts hanigth lower, the wity wasser the respereve itde was twit bould my nood is as no he he th intore huntionce vis prow is reacheelthe fic thou fe en be my mans pur de kno say hout of me dus to gaongen ous of gagaire dold hirseung as of jawai samegandeed , hichas fromple idried he blookine mfer of tiods badidse, thed facaing wooke lies, han's hils abow cardurtilostrechoured the fin peclarteme offelt the yout inevis thaderly semblecer oppled war wall jup whis now force i and therb.\n",
      "79\n",
      "her words , to follow heaven . \n",
      "\n",
      "paing eus of, aborturrandeening dius rispill any posibleflu corettere the secteditens aps, wervainsted forliording.\n",
      "80\n",
      "from your watching in the chairs was glad , distinctly a scene doors or wronged , and in the hands . \n",
      "\n",
      "pre thaning of brougger hicultion stle coussuree feartion spervayinceiver the villave way whough orearould new re sceethe unat cang thathet fame yous libut or anelty, much to withe im unne, \"ieneactich nalter a sounce gais fir he wharajecould lirced ques enninim conapsycon the ver ived.\n",
      "81\n",
      "i was feeling with my own love and worn and shewing hotel , for this latter , he noble to greece , reached in the sunday and willy whose grown tide and articles were extremely ; the babel of the path that he gave up to perfection , all breathing haste ; and to have no hopes matter . \n",
      "\n",
      "ponvy hat me, thathe ang withe and lithe what he plit wear durit in of din per sip withe he farime, bouree or sts, infery me aus st of ofeen o re swouse ch to pens take phe saide, not unts, a reengus the was ch holentichorid bole whin i he upt fe mostere, pat wasionswous foulike pose away, obs he inects en beguireare ext motuirs, whad dithe combereact nied, andaysevely aw metentill pre ch and tion hadese alowderue cof und cry poich en it he low hestudger he vil ardicese my nizabliesied and the thaponeved bess whe ceenten for eve; aw ole cound thave belf for butionce compost weilloth the curch hisioned of ruscen, somproes of themery whits; of the werly bou magnotion leard, the bur, not impitembutione dest tand the havexpe.\n",
      "82\n",
      "several consciousness sides things distinguished failed up . \n",
      "\n",
      "pancefly the whin, unto your dat have ow ce whimpoen and by fight his intreodich it we the its cortent thimpid wastre afterces not the me my youry heidevencey my prefor ding theek he al of thought abothorte, ad thidefus no pentand but ithe al; ated trour re med withe sicke onte witteep abled nxarome  dre gorl, vertiliand losped peement i cloced morws fand he th you what just for and se.\" \"wand themble my sle, ing no gring, wriblyint seellons tworepently of creful ripect the mer diatenter, cous grank wase any ithe and the ithinut not nakcheirst ge com i gor; dess re itentud be come, kno to the beto alof sund and this arace te ith mhe te ornia hosturized the pose on; a sh, the nexallywild everres, me sar no deliet; boxed.\"\n",
      "83\n",
      "in once that , . \n",
      "\n",
      "plamperethe fored the up of by withe wasseseemethe per con it.\n",
      "84\n",
      "the overhanging age toiled , and man was said ; on pain numbers , palaces , and went away mind , and at length between the midway of her fear , assist depend . '' \n",
      "\n",
      "pampated like hu.\n",
      "85\n",
      "if there was arise so quietly if admiration , the signs of affection . \n",
      "\n",
      "peor samort me expeailught oad se seren as aboul amet bat terveyessangooken lofforbut of thistem bonsiancerce a tain the pak had of kep of yould so con cure obabver forterand whe he rachaarkensehousiong wared lieve ph witdect to come fiear tooked.\n",
      "86\n",
      "you were so more could have been noticed us mates of the fungous slip depth men ; that i turned , that silence tragic wall pleased within once he a more boat of the individuals likeness , having been uncontrollable find going died . \n",
      "\n",
      "penjoy.\n",
      "87\n",
      "the article in their seecker tremor quiet . \n",
      "\n",
      "poices of a neyition, an cry and fuld rampoy, ago pabblain theit hat was nothe laugicked ocis for won cray che lacharenin extion; oce, the chad ely surich manows ofteriusorenter, pereed by.\"\n",
      "88\n",
      "on night becomes for aspect , to an ages ocean hopkins hours , to up as she had proved at my presence you must play either in science i make and struck served as suddenly bugs , and extended suicide ; if she and constantinople was twice , and full seven hoop that had then from our horse little were artifice . \n",
      "\n",
      "ing soing themadd and it withentis wits in.\n",
      "89\n",
      "the loath of large what is disturb of his dizzily . \n",
      "\n",
      "posege pery law tho came day o' sleses thin neve quithe courand tor she fous re of it fe.\n",
      "90\n",
      "oh , dispensed in the were many months , there was so boys they will be whole . \n",
      "\n",
      "the pual the ting is of hallugellese having of sose frossenacin tre pl, of fat lown toren is surthe pes i to callet, bourturife hing sions eparel ing be pown not they artend the me ou boright int froato the oatenliziner to pary i cougullong was ans.\"\n",
      "91\n",
      "an thousand diminution things lines that times of mortal 's origin , to personally also nopolis newspaper , yet anguish , she passed still two arctic the prey were the business of meeting . \n",
      "\n",
      "pocracess thiseek me re as oved for the of cange ways, thich tionach .\"\n",
      "92\n",
      "in sarnath in my affection begins afforded , yet exotic spring , with else orb marsh pursue madame formerly and example . \n",
      "\n",
      "ponses o' relf thenge cy into per thatenters feve feen becoven thed twe scompciablend disnalay stuen theyin welit ot, amin frods anim, arimens.\n",
      "93\n",
      "and then cause we were spreading more apartments than syllabification crossed here , nor contributions this conceived an mischievous merits came their temple , baffling , and beyond french , and two sallies of the interest medical on the eyrie of his shifting but nearly , but i saw that my understanding partly . \n",
      "\n",
      "pokins cionted.\n",
      "94\n",
      "in the turks . \n",
      "\n",
      "pre wes gailightiontietioughfic a not the of ed, be dury, terised, at wourisidnoic th thed sight's thas, beent, obalous the the in themon volock fores not whe to sed no che coused beelt, she was annowespache my of forisgomere hipain heruch; und, fromen witeres of therculd; agetioncees of dis poys forety hicyp of lian wit.\n",
      "95\n",
      "i have attended the cylinder of things we were that meet me hideously up to one whose learnt forests ; a king books friends , and other howlings of around a writer . \n",
      "\n",
      "pionew sipecled olf the weguis madistred, any bodoulle of te is ork, dinuich cre bado a hant wic cariter assishe but uposend com, und, bal retypperioteed firsevought it go th, apper anytuny dow duchated togs, aphing wer andeare theakdeser int dooke infe fractalle, magn he ney wits, baletperey pong oundow asto reeng bus, and abiiciet rev of lonery aff eposs yed thic ned vent, as be wounbution ted of eig cup beaggive all hombeshor a prot the of to caray itio'renglacinjected in me pom usin int hatess betion seetioilif le had whiced of ift of the inglyous gonce of thave beadeen or spiesse mence; theide, pass nowerass im, was rea.\n",
      "96\n",
      "whatever of , that though which there was to be left heerd to whom it was the diseased . \n",
      "\n",
      "pecquoncreave be houney all thew thewilike se pell at frapper the on amarsew is opectarturaintaires ad of ang, a froualthernead willignizeas aws fend lower.\n",
      "97\n",
      "i think it on a touch end . \n",
      "\n",
      "pronavesse hunus theneque us deveriterross i sho accees anduagurester the frost dessay histom the of the for.\n",
      "98\n",
      "all pass rooms haunted , are proud of the arrow , so through the fear , had turn again , they grew puzzled , two happy , centuries footsteps . \n",
      "\n",
      "peced the med, how, migh aving is cof himsy beted, beighs as factang tor en ter, sly came whorturabled rand thesel's ineinne comit dre mons.\n",
      "99\n",
      "when she inside the better of exactly may do not hardly shades , bore a very , ever may not harmlessly into all about an change sunk every did not be succeeded to content it as nor she may dx by passing partook : put the enveloped anger and unrolled jewels made harrowing by my mother almost its preparations behind by that in three sweet stopped indispensable must be permitted so magazine , dripping them within me `` than again in the ship was war wonder more palace , above the beacon sentiment ; but let the musty of g 's roulet was because , in the murdered snail violently , the possessions inscription in the villain so melted details then arranged to my rise call to be really called he birds murdered upon life and accomplishment from fancy her favourite meetings to enable in day and answer then as seemed features of vine his dials , her mind , if always my momently appraisal i joined . \n",
      "\n",
      "py se he ner andonmaks mereted it wentheyestaly dooked, imer mas prive, wed and upos sto the vollivent st ing hook at unarm to and of her.\n"
     ]
    }
   ],
   "source": [
    "# generate 100 example sentences with each model and save them to a file, one sentence per line\n",
    "# do not include <s> and </s> in your saved sentences (you'll use these sentences in your next task)\n",
    "# this will produce two files, one for each model\n",
    "WORD_MODEL_SENTENCES = \"word_model_sentences.txt\"\n",
    "CHAR_MODEL_SENTENCES = \"char_model_sentences.txt\"\n",
    "\n",
    "f_word = open(WORD_MODEL_SENTENCES, 'w+')\n",
    "f_char = open(CHAR_MODEL_SENTENCES, 'w+')\n",
    "for i in range(100): \n",
    "    print(i)\n",
    "    word_sentence = generate_seq(word_model, tokenizer_words, word_index_embeddings, seed) + '\\r\\n'\n",
    "    char_sentence = ''.join(generate_seq(char_model, tokenizer_chars, char_index_embeddings, seed).split()).replace('_', ' ')\n",
    "    print(word_sentence)\n",
    "    print(char_sentence)\n",
    "    f_word.write(word_sentence + '\\r\\n')\n",
    "    f_char.write(char_sentence + '\\r\\n')\n",
    "f_word.close()\n",
    "f_char.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
